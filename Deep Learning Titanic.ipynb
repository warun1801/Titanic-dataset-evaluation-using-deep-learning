{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    891\n",
       "Survived       891\n",
       "Pclass         891\n",
       "Name           891\n",
       "Sex            891\n",
       "Age            714\n",
       "SibSp          891\n",
       "Parch          891\n",
       "Ticket         891\n",
       "Fare           891\n",
       "Cabin          204\n",
       "Embarked       889\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in train_data:\n",
    "    print i if i[embarked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C', 'Q', 'S', nan}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_data['Embarked'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "def nan_padding(data, columns):\n",
    "    for column in columns:\n",
    "        imputer=Imputer()\n",
    "        data[column]=imputer.fit_transform(data[column].values.reshape(-1,1))\n",
    "    return data\n",
    "\n",
    "\n",
    "nan_columns = [\"Age\", \"SibSp\", \"Parch\"]\n",
    "train_data = nan_padding(train_data,nan_columns)\n",
    "test_data = nan_padding(test_data,nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    891\n",
       "Survived       891\n",
       "Pclass         891\n",
       "Name           891\n",
       "Sex            891\n",
       "Age            891\n",
       "SibSp          891\n",
       "Parch          891\n",
       "Ticket         891\n",
       "Fare           891\n",
       "Cabin          204\n",
       "Embarked       889\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_id = test_data['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropColumns(data,columns):\n",
    "    for column in columns:\n",
    "        return data.drop(columns,axis=1)\n",
    "        \n",
    "        \n",
    "drop_columns = [\"PassengerId\",\"Name\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"]\n",
    "train_data = dropColumns(train_data,drop_columns)\n",
    "test_data = dropColumns(test_data,drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch\n",
       "0         0       3    male  22.0    1.0    0.0\n",
       "1         1       1  female  38.0    1.0    0.0\n",
       "2         1       3  female  26.0    0.0    0.0\n",
       "3         1       1  female  35.0    1.0    0.0\n",
       "4         0       3    male  35.0    0.0    0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_data(data, columns):\n",
    "    for column in columns:\n",
    "        data = pd.concat([data, pd.get_dummies(data[column], prefix=column)], axis=1)\n",
    "        data = data.drop(column, axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "dummy_columns = [\"Pclass\"]\n",
    "train_data=dummy_data(train_data, dummy_columns)\n",
    "test_data=dummy_data(test_data, dummy_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived     Sex   Age  SibSp  Parch  Pclass_1  Pclass_2  Pclass_3\n",
       "0         0    male  22.0    1.0    0.0         0         0         1\n",
       "1         1  female  38.0    1.0    0.0         1         0         0\n",
       "2         1  female  26.0    0.0    0.0         0         0         1\n",
       "3         1  female  35.0    1.0    0.0         1         0         0\n",
       "4         0    male  35.0    0.0    0.0         0         0         1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def lb(data):\n",
    "    le = LabelEncoder()\n",
    "    le.fit([\"male\",\"female\"])\n",
    "    data[\"Sex\"] = le.transform(data[\"Sex\"])\n",
    "    return data\n",
    "\n",
    "train_data = lb(train_data)\n",
    "test_data = lb(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Sex   Age  SibSp  Parch  Pclass_1  Pclass_2  Pclass_3\n",
       "0         0    1  22.0    1.0    0.0         0         0         1\n",
       "1         1    0  38.0    1.0    0.0         1         0         0\n",
       "2         1    0  26.0    0.0    0.0         0         0         1\n",
       "3         1    0  35.0    1.0    0.0         1         0         0\n",
       "4         0    1  35.0    0.0    0.0         0         0         1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Sex       Age  SibSp  Parch  Pclass_1  Pclass_2  Pclass_3\n",
       "0         0    1  0.271174    1.0    0.0         0         0         1\n",
       "1         1    0  0.472229    1.0    0.0         1         0         0\n",
       "2         1    0  0.321438    0.0    0.0         0         0         1\n",
       "3         1    0  0.434531    1.0    0.0         1         0         0\n",
       "4         0    1  0.434531    0.0    0.0         0         0         1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_age(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    data[\"Age\"] = scaler.fit_transform(data[\"Age\"].values.reshape(-1,1))\n",
    "    return data\n",
    "train_data = normalize_age(train_data)\n",
    "test_data = normalize_age(test_data)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x:(712, 7)\n",
      "train_y:(712, 1)\n",
      "train_y content:[[0]\n",
      " [0]\n",
      " [0]]\n",
      "valid_x:(179, 7)\n",
      "valid_y:(179, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_valid_test_data(data, fraction=(1 - 0.8)):\n",
    "    data_y = data[\"Survived\"]\n",
    "    lb = LabelBinarizer()\n",
    "    data_y = lb.fit_transform(data_y)\n",
    "\n",
    "    data_x = data.drop([\"Survived\"], axis=1)\n",
    "\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data_x, data_y, test_size=fraction)\n",
    "\n",
    "    return train_x.values, train_y, valid_x, valid_y\n",
    "\n",
    "train_x, train_y, valid_x, valid_y = split_valid_test_data(train_data)\n",
    "print(\"train_x:{}\".format(train_x.shape))\n",
    "print(\"train_y:{}\".format(train_y.shape))\n",
    "print(\"train_y content:{}\".format(train_y[:3]))\n",
    "\n",
    "print(\"valid_x:{}\".format(valid_x.shape))\n",
    "print(\"valid_y:{}\".format(valid_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "def build_neural_network(hidden_units=10):\n",
    "    tf.reset_default_graph()\n",
    "    inputs = tf.placeholder(tf.float32, shape=[None, train_x.shape[1]])\n",
    "    labels = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    is_training=tf.Variable(True,dtype=tf.bool)\n",
    "    \n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    fc = tf.layers.dense(inputs, hidden_units, activation=None,kernel_initializer=initializer)\n",
    "    fc=tf.layers.batch_normalization(fc, training=is_training)\n",
    "    fc=tf.nn.relu(fc)\n",
    "    \n",
    "    logits = tf.layers.dense(fc, 1, activation=None)\n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    predicted = tf.nn.sigmoid(logits)\n",
    "    correct_pred = tf.equal(tf.round(predicted), labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    \n",
    "    \n",
    "# Export the nodes \n",
    "    export_nodes = ['inputs', 'labels', 'learning_rate','is_training', 'logits',\n",
    "                    'cost', 'optimizer', 'predicted', 'accuracy']\n",
    "    Graph = namedtuple('Graph', export_nodes)\n",
    "    local_dict = locals()\n",
    "    graph = Graph(*[local_dict[each] for each in export_nodes])\n",
    "\n",
    "    return graph\n",
    "\n",
    "model = build_neural_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data_x,data_y,batch_size=32):\n",
    "    batch_n=len(data_x)//batch_size\n",
    "    for i in range(batch_n):\n",
    "        batch_x=data_x[i*batch_size:(i+1)*batch_size]\n",
    "        batch_y=data_y[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        yield batch_x,batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "train_collect = 50\n",
    "train_print = train_collect*2\n",
    "\n",
    "learning_rate_value = 0.001\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_collect = []\n",
    "train_loss_collect = []\n",
    "train_acc_collect = []\n",
    "valid_loss_collect = []\n",
    "valid_acc_collect = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/200 Train Loss: 0.5058 Train Acc: 0.7135\n",
      "Epoch: 3/200 Validation Loss: 0.5792 Validation Acc: 0.7263\n",
      "Epoch: 5/200 Train Loss: 0.4408 Train Acc: 0.8076\n",
      "Epoch: 5/200 Validation Loss: 0.5122 Validation Acc: 0.7486\n",
      "Epoch: 7/200 Train Loss: 0.4148 Train Acc: 0.8076\n",
      "Epoch: 7/200 Validation Loss: 0.4767 Validation Acc: 0.7598\n",
      "Epoch: 10/200 Train Loss: 0.4052 Train Acc: 0.8230\n",
      "Epoch: 10/200 Validation Loss: 0.4578 Validation Acc: 0.7933\n",
      "Epoch: 12/200 Train Loss: 0.4007 Train Acc: 0.8287\n",
      "Epoch: 12/200 Validation Loss: 0.4493 Validation Acc: 0.7933\n",
      "Epoch: 14/200 Train Loss: 0.3978 Train Acc: 0.8258\n",
      "Epoch: 14/200 Validation Loss: 0.4494 Validation Acc: 0.8101\n",
      "Epoch: 16/200 Train Loss: 0.3959 Train Acc: 0.8272\n",
      "Epoch: 16/200 Validation Loss: 0.4464 Validation Acc: 0.8101\n",
      "Epoch: 19/200 Train Loss: 0.3944 Train Acc: 0.8301\n",
      "Epoch: 19/200 Validation Loss: 0.4388 Validation Acc: 0.8212\n",
      "Epoch: 21/200 Train Loss: 0.3931 Train Acc: 0.8343\n",
      "Epoch: 21/200 Validation Loss: 0.4391 Validation Acc: 0.8268\n",
      "Epoch: 23/200 Train Loss: 0.3920 Train Acc: 0.8329\n",
      "Epoch: 23/200 Validation Loss: 0.4387 Validation Acc: 0.8268\n",
      "Epoch: 25/200 Train Loss: 0.3910 Train Acc: 0.8329\n",
      "Epoch: 25/200 Validation Loss: 0.4404 Validation Acc: 0.8268\n",
      "Epoch: 28/200 Train Loss: 0.3904 Train Acc: 0.8329\n",
      "Epoch: 28/200 Validation Loss: 0.4388 Validation Acc: 0.8212\n",
      "Epoch: 30/200 Train Loss: 0.3889 Train Acc: 0.8371\n",
      "Epoch: 30/200 Validation Loss: 0.4420 Validation Acc: 0.8212\n",
      "Epoch: 32/200 Train Loss: 0.3883 Train Acc: 0.8343\n",
      "Epoch: 32/200 Validation Loss: 0.4439 Validation Acc: 0.8212\n",
      "Epoch: 35/200 Train Loss: 0.3875 Train Acc: 0.8371\n",
      "Epoch: 35/200 Validation Loss: 0.4424 Validation Acc: 0.8212\n",
      "Epoch: 37/200 Train Loss: 0.3863 Train Acc: 0.8357\n",
      "Epoch: 37/200 Validation Loss: 0.4425 Validation Acc: 0.8212\n",
      "Epoch: 39/200 Train Loss: 0.3851 Train Acc: 0.8371\n",
      "Epoch: 39/200 Validation Loss: 0.4421 Validation Acc: 0.8212\n",
      "Epoch: 41/200 Train Loss: 0.3837 Train Acc: 0.8385\n",
      "Epoch: 41/200 Validation Loss: 0.4429 Validation Acc: 0.8268\n",
      "Epoch: 44/200 Train Loss: 0.3827 Train Acc: 0.8357\n",
      "Epoch: 44/200 Validation Loss: 0.4448 Validation Acc: 0.8212\n",
      "Epoch: 46/200 Train Loss: 0.3819 Train Acc: 0.8343\n",
      "Epoch: 46/200 Validation Loss: 0.4428 Validation Acc: 0.8212\n",
      "Epoch: 48/200 Train Loss: 0.3812 Train Acc: 0.8343\n",
      "Epoch: 48/200 Validation Loss: 0.4417 Validation Acc: 0.8212\n",
      "Epoch: 50/200 Train Loss: 0.3799 Train Acc: 0.8357\n",
      "Epoch: 50/200 Validation Loss: 0.4407 Validation Acc: 0.8212\n",
      "Epoch: 53/200 Train Loss: 0.3792 Train Acc: 0.8343\n",
      "Epoch: 53/200 Validation Loss: 0.4395 Validation Acc: 0.8156\n",
      "Epoch: 55/200 Train Loss: 0.3786 Train Acc: 0.8343\n",
      "Epoch: 55/200 Validation Loss: 0.4400 Validation Acc: 0.8212\n",
      "Epoch: 57/200 Train Loss: 0.3779 Train Acc: 0.8343\n",
      "Epoch: 57/200 Validation Loss: 0.4425 Validation Acc: 0.8212\n",
      "Epoch: 60/200 Train Loss: 0.3769 Train Acc: 0.8343\n",
      "Epoch: 60/200 Validation Loss: 0.4425 Validation Acc: 0.8156\n",
      "Epoch: 62/200 Train Loss: 0.3763 Train Acc: 0.8343\n",
      "Epoch: 62/200 Validation Loss: 0.4422 Validation Acc: 0.8156\n",
      "Epoch: 64/200 Train Loss: 0.3755 Train Acc: 0.8371\n",
      "Epoch: 64/200 Validation Loss: 0.4406 Validation Acc: 0.8156\n",
      "Epoch: 66/200 Train Loss: 0.3740 Train Acc: 0.8329\n",
      "Epoch: 66/200 Validation Loss: 0.4464 Validation Acc: 0.8156\n",
      "Epoch: 69/200 Train Loss: 0.3732 Train Acc: 0.8357\n",
      "Epoch: 69/200 Validation Loss: 0.4447 Validation Acc: 0.8156\n",
      "Epoch: 71/200 Train Loss: 0.3727 Train Acc: 0.8371\n",
      "Epoch: 71/200 Validation Loss: 0.4412 Validation Acc: 0.8212\n",
      "Epoch: 73/200 Train Loss: 0.3721 Train Acc: 0.8357\n",
      "Epoch: 73/200 Validation Loss: 0.4432 Validation Acc: 0.8212\n",
      "Epoch: 75/200 Train Loss: 0.3716 Train Acc: 0.8357\n",
      "Epoch: 75/200 Validation Loss: 0.4428 Validation Acc: 0.8268\n",
      "Epoch: 78/200 Train Loss: 0.3708 Train Acc: 0.8399\n",
      "Epoch: 78/200 Validation Loss: 0.4446 Validation Acc: 0.8212\n",
      "Epoch: 80/200 Train Loss: 0.3702 Train Acc: 0.8399\n",
      "Epoch: 80/200 Validation Loss: 0.4465 Validation Acc: 0.8268\n",
      "Epoch: 82/200 Train Loss: 0.3696 Train Acc: 0.8413\n",
      "Epoch: 82/200 Validation Loss: 0.4492 Validation Acc: 0.8268\n",
      "Epoch: 85/200 Train Loss: 0.3689 Train Acc: 0.8441\n",
      "Epoch: 85/200 Validation Loss: 0.4497 Validation Acc: 0.8212\n",
      "Epoch: 87/200 Train Loss: 0.3684 Train Acc: 0.8413\n",
      "Epoch: 87/200 Validation Loss: 0.4523 Validation Acc: 0.8156\n",
      "Epoch: 89/200 Train Loss: 0.3676 Train Acc: 0.8413\n",
      "Epoch: 89/200 Validation Loss: 0.4522 Validation Acc: 0.8156\n",
      "Epoch: 91/200 Train Loss: 0.3653 Train Acc: 0.8399\n",
      "Epoch: 91/200 Validation Loss: 0.4568 Validation Acc: 0.8212\n",
      "Epoch: 94/200 Train Loss: 0.3627 Train Acc: 0.8469\n",
      "Epoch: 94/200 Validation Loss: 0.4653 Validation Acc: 0.8268\n",
      "Epoch: 96/200 Train Loss: 0.3611 Train Acc: 0.8483\n",
      "Epoch: 96/200 Validation Loss: 0.4674 Validation Acc: 0.8212\n",
      "Epoch: 98/200 Train Loss: 0.3601 Train Acc: 0.8539\n",
      "Epoch: 98/200 Validation Loss: 0.4683 Validation Acc: 0.8212\n",
      "Epoch: 100/200 Train Loss: 0.3572 Train Acc: 0.8539\n",
      "Epoch: 100/200 Validation Loss: 0.4841 Validation Acc: 0.8045\n",
      "Epoch: 103/200 Train Loss: 0.3547 Train Acc: 0.8553\n",
      "Epoch: 103/200 Validation Loss: 0.4888 Validation Acc: 0.7933\n",
      "Epoch: 105/200 Train Loss: 0.3536 Train Acc: 0.8553\n",
      "Epoch: 105/200 Validation Loss: 0.4746 Validation Acc: 0.8212\n",
      "Epoch: 107/200 Train Loss: 0.3528 Train Acc: 0.8553\n",
      "Epoch: 107/200 Validation Loss: 0.4748 Validation Acc: 0.8268\n",
      "Epoch: 110/200 Train Loss: 0.3521 Train Acc: 0.8567\n",
      "Epoch: 110/200 Validation Loss: 0.4737 Validation Acc: 0.8268\n",
      "Epoch: 112/200 Train Loss: 0.3516 Train Acc: 0.8567\n",
      "Epoch: 112/200 Validation Loss: 0.4807 Validation Acc: 0.8212\n",
      "Epoch: 114/200 Train Loss: 0.3512 Train Acc: 0.8567\n",
      "Epoch: 114/200 Validation Loss: 0.4861 Validation Acc: 0.8212\n",
      "Epoch: 116/200 Train Loss: 0.3508 Train Acc: 0.8567\n",
      "Epoch: 116/200 Validation Loss: 0.4875 Validation Acc: 0.8156\n",
      "Epoch: 119/200 Train Loss: 0.3504 Train Acc: 0.8553\n",
      "Epoch: 119/200 Validation Loss: 0.4879 Validation Acc: 0.8156\n",
      "Epoch: 121/200 Train Loss: 0.3498 Train Acc: 0.8539\n",
      "Epoch: 121/200 Validation Loss: 0.4933 Validation Acc: 0.8156\n",
      "Epoch: 123/200 Train Loss: 0.3494 Train Acc: 0.8553\n",
      "Epoch: 123/200 Validation Loss: 0.4960 Validation Acc: 0.8212\n",
      "Epoch: 125/200 Train Loss: 0.3491 Train Acc: 0.8539\n",
      "Epoch: 125/200 Validation Loss: 0.4939 Validation Acc: 0.8212\n",
      "Epoch: 128/200 Train Loss: 0.3489 Train Acc: 0.8539\n",
      "Epoch: 128/200 Validation Loss: 0.4984 Validation Acc: 0.8101\n",
      "Epoch: 130/200 Train Loss: 0.3487 Train Acc: 0.8539\n",
      "Epoch: 130/200 Validation Loss: 0.4908 Validation Acc: 0.8268\n",
      "Epoch: 132/200 Train Loss: 0.3485 Train Acc: 0.8539\n",
      "Epoch: 132/200 Validation Loss: 0.4987 Validation Acc: 0.8156\n",
      "Epoch: 135/200 Train Loss: 0.3481 Train Acc: 0.8539\n",
      "Epoch: 135/200 Validation Loss: 0.5082 Validation Acc: 0.8101\n",
      "Epoch: 137/200 Train Loss: 0.3479 Train Acc: 0.8525\n",
      "Epoch: 137/200 Validation Loss: 0.4992 Validation Acc: 0.8156\n",
      "Epoch: 139/200 Train Loss: 0.3478 Train Acc: 0.8525\n",
      "Epoch: 139/200 Validation Loss: 0.5018 Validation Acc: 0.8268\n",
      "Epoch: 141/200 Train Loss: 0.3476 Train Acc: 0.8525\n",
      "Epoch: 141/200 Validation Loss: 0.5123 Validation Acc: 0.8101\n",
      "Epoch: 144/200 Train Loss: 0.3476 Train Acc: 0.8525\n",
      "Epoch: 144/200 Validation Loss: 0.5187 Validation Acc: 0.8101\n",
      "Epoch: 146/200 Train Loss: 0.3474 Train Acc: 0.8525\n",
      "Epoch: 146/200 Validation Loss: 0.5169 Validation Acc: 0.8045\n",
      "Epoch: 148/200 Train Loss: 0.3473 Train Acc: 0.8525\n",
      "Epoch: 148/200 Validation Loss: 0.5188 Validation Acc: 0.8156\n",
      "Epoch: 150/200 Train Loss: 0.3473 Train Acc: 0.8511\n",
      "Epoch: 150/200 Validation Loss: 0.5215 Validation Acc: 0.8156\n",
      "Epoch: 153/200 Train Loss: 0.3472 Train Acc: 0.8525\n",
      "Epoch: 153/200 Validation Loss: 0.5138 Validation Acc: 0.8268\n",
      "Epoch: 155/200 Train Loss: 0.3472 Train Acc: 0.8525\n",
      "Epoch: 155/200 Validation Loss: 0.5157 Validation Acc: 0.8268\n",
      "Epoch: 157/200 Train Loss: 0.3471 Train Acc: 0.8525\n",
      "Epoch: 157/200 Validation Loss: 0.5138 Validation Acc: 0.8045\n",
      "Epoch: 160/200 Train Loss: 0.3471 Train Acc: 0.8511\n",
      "Epoch: 160/200 Validation Loss: 0.5162 Validation Acc: 0.8268\n",
      "Epoch: 162/200 Train Loss: 0.3471 Train Acc: 0.8511\n",
      "Epoch: 162/200 Validation Loss: 0.5210 Validation Acc: 0.8156\n",
      "Epoch: 164/200 Train Loss: 0.3470 Train Acc: 0.8511\n",
      "Epoch: 164/200 Validation Loss: 0.5309 Validation Acc: 0.8101\n",
      "Epoch: 166/200 Train Loss: 0.3470 Train Acc: 0.8511\n",
      "Epoch: 166/200 Validation Loss: 0.5317 Validation Acc: 0.8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 169/200 Train Loss: 0.3470 Train Acc: 0.8511\n",
      "Epoch: 169/200 Validation Loss: 0.5519 Validation Acc: 0.7709\n",
      "Epoch: 171/200 Train Loss: 0.3470 Train Acc: 0.8511\n",
      "Epoch: 171/200 Validation Loss: 0.5450 Validation Acc: 0.7765\n",
      "Epoch: 173/200 Train Loss: 0.3470 Train Acc: 0.8511\n",
      "Epoch: 173/200 Validation Loss: 0.5279 Validation Acc: 0.8212\n",
      "Epoch: 175/200 Train Loss: 0.3470 Train Acc: 0.8511\n",
      "Epoch: 175/200 Validation Loss: 0.5306 Validation Acc: 0.8045\n",
      "Epoch: 178/200 Train Loss: 0.3470 Train Acc: 0.8511\n",
      "Epoch: 178/200 Validation Loss: 0.5268 Validation Acc: 0.8045\n",
      "Epoch: 180/200 Train Loss: 0.3469 Train Acc: 0.8511\n",
      "Epoch: 180/200 Validation Loss: 0.5302 Validation Acc: 0.8156\n",
      "Epoch: 182/200 Train Loss: 0.3470 Train Acc: 0.8511\n",
      "Epoch: 182/200 Validation Loss: 0.5265 Validation Acc: 0.8212\n",
      "Epoch: 185/200 Train Loss: 0.3469 Train Acc: 0.8511\n",
      "Epoch: 185/200 Validation Loss: 0.5157 Validation Acc: 0.8268\n",
      "Epoch: 187/200 Train Loss: 0.3469 Train Acc: 0.8511\n",
      "Epoch: 187/200 Validation Loss: 0.5175 Validation Acc: 0.8268\n",
      "Epoch: 189/200 Train Loss: 0.3469 Train Acc: 0.8511\n",
      "Epoch: 189/200 Validation Loss: 0.5282 Validation Acc: 0.8101\n",
      "Epoch: 191/200 Train Loss: 0.3469 Train Acc: 0.8511\n",
      "Epoch: 191/200 Validation Loss: 0.5211 Validation Acc: 0.8212\n",
      "Epoch: 194/200 Train Loss: 0.3469 Train Acc: 0.8511\n",
      "Epoch: 194/200 Validation Loss: 0.5202 Validation Acc: 0.8268\n",
      "Epoch: 196/200 Train Loss: 0.3469 Train Acc: 0.8511\n",
      "Epoch: 196/200 Validation Loss: 0.5192 Validation Acc: 0.8268\n",
      "Epoch: 198/200 Train Loss: 0.3469 Train Acc: 0.8511\n",
      "Epoch: 198/200 Validation Loss: 0.5184 Validation Acc: 0.8268\n",
      "Epoch: 200/200 Train Loss: 0.3469 Train Acc: 0.8511\n",
      "Epoch: 200/200 Validation Loss: 0.5246 Validation Acc: 0.8268\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration=0\n",
    "    for e in range(epochs):\n",
    "        for batch_x,batch_y in get_batch(train_x,train_y,batch_size):\n",
    "            iteration+=1\n",
    "            feed = {model.inputs: train_x,\n",
    "                    model.labels: train_y,\n",
    "                    model.learning_rate: learning_rate_value,\n",
    "                    model.is_training:True\n",
    "                   }\n",
    "\n",
    "            train_loss, _, train_acc = sess.run([model.cost, model.optimizer, model.accuracy], feed_dict=feed)\n",
    "            \n",
    "            if iteration % train_collect == 0:\n",
    "                x_collect.append(e)\n",
    "                train_loss_collect.append(train_loss)\n",
    "                train_acc_collect.append(train_acc)\n",
    "                if iteration % train_print==0:\n",
    "                     print(\"Epoch: {}/{}\".format(e + 1, epochs),\n",
    "                      \"Train Loss: {:.4f}\".format(train_loss),\n",
    "                      \"Train Acc: {:.4f}\".format(train_acc))\n",
    "                        \n",
    "                feed = {model.inputs: valid_x,\n",
    "                        model.labels: valid_y,\n",
    "                        model.is_training:False\n",
    "                       }\n",
    "                val_loss, val_acc = sess.run([model.cost, model.accuracy], feed_dict=feed)\n",
    "                valid_loss_collect.append(val_loss)\n",
    "                valid_acc_collect.append(val_acc)\n",
    "                \n",
    "                if iteration % train_print==0:\n",
    "                    print(\"Epoch: {}/{}\".format(e + 1, epochs),\n",
    "                      \"Validation Loss: {:.4f}\".format(val_loss),\n",
    "                      \"Validation Acc: {:.4f}\".format(val_acc))\n",
    "                \n",
    "    feed={\n",
    "            model.inputs:test_data,\n",
    "            model.is_training:False\n",
    "        }\n",
    "    test_predict=sess.run(model.predicted,feed_dict=feed)\n",
    "    test_predict[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "binarizer=Binarizer(0.5)\n",
    "test_predict_result=binarizer.fit_transform(test_predict)\n",
    "test_predict_result=test_predict_result.astype(np.int32)\n",
    "test_predict_result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0\n",
       "5          897         0\n",
       "6          898         1\n",
       "7          899         0\n",
       "8          900         1\n",
       "9          901         0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passenger_id=tester_id.copy()\n",
    "evaluation=passenger_id.to_frame()\n",
    "evaluation[\"Survived\"]=test_predict_result\n",
    "evaluation[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.to_csv(\"predictions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
